import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score
import time
from collections import defaultdict
import random

def learning_curve(model_class, x_data, y_data, x_test, y_test, text_processor,
                   train_sizes=None, cv_folds=3, model_params=None,
                   title="Learning Curve", figsize=(12, 8)):
    """
    Váº½ learning curve Ä‘á»ƒ kiá»ƒm Ä‘á»‹nh underfitting vÃ  overfitting

    Args:
        model_class: Class cá»§a model (NaiveBayes hoáº·c NaiveBayesCUDAOptimized)
        x_data: Dá»¯ liá»‡u vÄƒn báº£n Ä‘áº§y Ä‘á»§
        y_data: NhÃ£n Ä‘áº§y Ä‘á»§ tÆ°Æ¡ng á»©ng
        x_test: Dá»¯ liá»‡u test
        y_test: NhÃ£n test
        text_processor: TextProcessor Ä‘á»ƒ xá»­ lÃ½ vÄƒn báº£n
        train_sizes: List kÃ­ch thÆ°á»›c táº­p train (máº·c Ä‘á»‹nh tá»« 500 Ä‘áº¿n toÃ n bá»™)
        cv_folds: Sá»‘ folds cho cross-validation
        model_params: Parameters cho model
        title: TiÃªu Ä‘á» biá»ƒu Ä‘á»“
        figsize: KÃ­ch thÆ°á»›c figure

    Returns:
        dict: Káº¿t quáº£ learning curve
    """

    if model_params is None:
        model_params = {'alpha': 0.001}

    # TÃ­nh sá»‘ lÆ°á»£ng máº«u trÃªn má»—i lá»›p
    class_counts = defaultdict(int)
    for label in y_data:
        class_counts[label] += 1

    min_samples_per_class = min(class_counts.values())
    print(f"Sá»‘ máº«u tá»‘i thiá»ƒu trÃªn má»—i lá»›p: {min_samples_per_class}")
    print(f"PhÃ¢n phá»‘i lá»›p: {dict(class_counts)}")

    # Thiáº¿t láº­p train_sizes máº·c Ä‘á»‹nh
    if train_sizes is None:
        max_size_per_class = min(3500, min_samples_per_class)
        train_sizes = list(range(500, max_size_per_class + 1, 500))
        # ThÃªm má»™t sá»‘ kÃ­ch thÆ°á»›c nhá» hÆ¡n Ä‘á»ƒ tháº¥y rÃµ underfitting
        train_sizes = [100, 200] + train_sizes
        train_sizes = sorted(list(set(train_sizes)))

    print(f"KÃ­ch thÆ°á»›c train sáº½ test: {train_sizes}")

    # Chuáº©n bá»‹ dá»¯ liá»‡u theo lá»›p
    class_data = defaultdict(list)
    for i, label in enumerate(y_data):
        class_data[label].append((x_data[i], label))

    # Shuffle dá»¯ liá»‡u trong má»—i lá»›p
    for label in class_data:
        random.shuffle(class_data[label])

    # Xá»­ lÃ½ dá»¯ liá»‡u test má»™t láº§n
    print("Äang xá»­ lÃ½ dá»¯ liá»‡u test...")
    x_test_processed = text_processor.transform(x_test)

    # LÆ°u káº¿t quáº£
    results = {
        'train_sizes': [],
        'train_scores_mean': [],
        'train_scores_std': [],
        'test_scores_mean': [],
        'test_scores_std': [],
        'fit_times_mean': [],
        'fit_times_std': []
    }

    print("\n=== Báº®T Äáº¦U LEARNING CURVE ===")

    for size_per_class in train_sizes:
        print(f"\n--- Training vá»›i {size_per_class} máº«u/lá»›p ---")

        # Kiá»ƒm tra xem cÃ³ Ä‘á»§ dá»¯ liá»‡u khÃ´ng
        if size_per_class > min_samples_per_class:
            print(f"KhÃ´ng Ä‘á»§ dá»¯ liá»‡u cho {size_per_class} máº«u/lá»›p, bá» qua.")
            continue

        total_train_size = size_per_class * len(class_data)

        # Cross-validation
        train_scores = []
        test_scores = []
        fit_times = []

        for fold in range(cv_folds):
            print(f"  Fold {fold + 1}/{cv_folds}...")

            # Táº¡o táº­p train cho fold nÃ y
            fold_x_train = []
            fold_y_train = []

            for label, data_list in class_data.items():
                # Chia dá»¯ liá»‡u thÃ nh cv_folds pháº§n
                fold_size = len(data_list) // cv_folds
                start_idx = fold * fold_size
                end_idx = start_idx + fold_size

                # Láº¥y dá»¯ liá»‡u cho fold hiá»‡n táº¡i (pháº§n cÃ²n láº¡i lÃ m validation)
                fold_data = data_list[:start_idx] + data_list[end_idx:]

                # Láº¥y size_per_class máº«u Ä‘áº§u tiÃªn
                selected_data = fold_data[:size_per_class]

                for text, label_item in selected_data:
                    fold_x_train.append(text)
                    fold_y_train.append(label_item)

            # Xá»­ lÃ½ dá»¯ liá»‡u train cho fold nÃ y
            fold_x_train_processed = text_processor.transform(fold_x_train)
            feature_names = text_processor.get_feature_names()

            # Train model
            start_time = time.time()

            try:
                # Thá»­ GPU model trÆ°á»›c
                if 'use_gpu' in model_class.__init__.__code__.co_varnames:
                    model = model_class(use_gpu=True, **model_params)
                else:
                    model = model_class(**model_params)
            except:
                model = model_class(**model_params)

            model.fit(fold_x_train_processed, fold_y_train, feature_names)
            fit_time = time.time() - start_time
            fit_times.append(fit_time)

            # ÄÃ¡nh giÃ¡ trÃªn táº­p train
            train_pred = model.predict(fold_x_train_processed)
            train_accuracy = accuracy_score(fold_y_train, train_pred)
            train_scores.append(train_accuracy)

            # ÄÃ¡nh giÃ¡ trÃªn táº­p test
            test_pred = model.predict(x_test_processed)
            test_accuracy = accuracy_score(y_test, test_pred)
            test_scores.append(test_accuracy)

            print(f"    Train accuracy: {train_accuracy:.4f}")
            print(f"    Test accuracy: {test_accuracy:.4f}")
            print(f"    Fit time: {fit_time:.2f}s")

        # TÃ­nh trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n
        results['train_sizes'].append(total_train_size)
        results['train_scores_mean'].append(np.mean(train_scores))
        results['train_scores_std'].append(np.std(train_scores))
        results['test_scores_mean'].append(np.mean(test_scores))
        results['test_scores_std'].append(np.std(test_scores))
        results['fit_times_mean'].append(np.mean(fit_times))
        results['fit_times_std'].append(np.std(fit_times))

        print(f"  Trung bÃ¬nh - Train: {np.mean(train_scores):.4f} Â± {np.std(train_scores):.4f}")
        print(f"  Trung bÃ¬nh - Test: {np.mean(test_scores):.4f} Â± {np.std(test_scores):.4f}")

    # Váº½ biá»ƒu Ä‘á»“
    plot_learning_curve(results, title, figsize)

    # PhÃ¢n tÃ­ch káº¿t quáº£
    analyze_learning_curve(results)

    return results

def plot_learning_curve(results, title="Learning Curve", figsize=(12, 8)):
    """Váº½ biá»ƒu Ä‘á»“ learning curve"""

    plt.figure(figsize=figsize)

    train_sizes = results['train_sizes']
    train_scores_mean = results['train_scores_mean']
    train_scores_std = results['train_scores_std']
    test_scores_mean = results['test_scores_mean']
    test_scores_std = results['test_scores_std']

    # Váº½ Ä‘Æ°á»ng train score
    plt.plot(train_sizes, train_scores_mean, 'o-', color='blue',
             label='Training Accuracy', linewidth=2, markersize=8)
    plt.fill_between(train_sizes,
                     np.array(train_scores_mean) - np.array(train_scores_std),
                     np.array(train_scores_mean) + np.array(train_scores_std),
                     alpha=0.2, color='blue')

    # Váº½ Ä‘Æ°á»ng test score
    plt.plot(train_sizes, test_scores_mean, 'o-', color='red',
             label='Testing Accuracy', linewidth=2, markersize=8)
    plt.fill_between(train_sizes,
                     np.array(test_scores_mean) - np.array(test_scores_std),
                     np.array(test_scores_mean) + np.array(test_scores_std),
                     alpha=0.2, color='red')

    # TÃ¹y chá»‰nh biá»ƒu Ä‘á»“
    plt.xlabel('Training Set Size', fontsize=12)
    plt.ylabel('Accuracy Score', fontsize=12)
    plt.title(title, fontsize=14, fontweight='bold')
    plt.legend(loc='lower right', fontsize=11)
    plt.grid(True, alpha=0.3)

    # Thiáº¿t láº­p trá»¥c
    plt.ylim(0, 1.05)
    plt.xlim(min(train_sizes) * 0.9, max(train_sizes) * 1.1)

    # ThÃªm chÃº thÃ­ch vá» overfitting/underfitting
    max_gap = max(np.array(train_scores_mean) - np.array(test_scores_mean))
    plt.text(0.02, 0.98, f'Max Train-Test Gap: {max_gap:.3f}',
             transform=plt.gca().transAxes, fontsize=10,
             verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    plt.show()

def analyze_learning_curve(results):
    """PhÃ¢n tÃ­ch káº¿t quáº£ learning curve"""

    print("\n" + "="*60)
    print("PHÃ‚N TÃCH LEARNING CURVE")
    print("="*60)

    train_scores = np.array(results['train_scores_mean'])
    test_scores = np.array(results['test_scores_mean'])
    train_sizes = np.array(results['train_sizes'])

    # 1. PhÃ¢n tÃ­ch Underfitting
    print("\n1. PHÃ‚N TÃCH UNDERFITTING:")
    initial_train_score = train_scores[0]
    initial_test_score = test_scores[0]

    if initial_train_score < 0.7 or initial_test_score < 0.7:
        print("   âš ï¸  UNDERFITTING Ä‘Æ°á»£c phÃ¡t hiá»‡n!")
        print(f"   - Train accuracy ban Ä‘áº§u: {initial_train_score:.3f}")
        print(f"   - Test accuracy ban Ä‘áº§u: {initial_test_score:.3f}")
        print("   ğŸ“‹ Khuyáº¿n nghá»‹:")
        print("      â€¢ Giáº£m regularization (alpha)")
        print("      â€¢ TÄƒng sá»‘ lÆ°á»£ng features (max_features)")
        print("      â€¢ Thá»­ mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n")
    else:
        print("   âœ… KhÃ´ng cÃ³ dáº¥u hiá»‡u underfitting rÃµ rÃ ng")

    # 2. PhÃ¢n tÃ­ch Overfitting
    print("\n2. PHÃ‚N TÃCH OVERFITTING:")
    gaps = train_scores - test_scores
    max_gap = np.max(gaps)
    avg_gap = np.mean(gaps)

    print(f"   - Gap trung bÃ¬nh (Train - Test): {avg_gap:.3f}")
    print(f"   - Gap lá»›n nháº¥t: {max_gap:.3f}")

    if max_gap > 0.1:
        print("   âš ï¸  OVERFITTING Ä‘Æ°á»£c phÃ¡t hiá»‡n!")
        print("   ğŸ“‹ Khuyáº¿n nghá»‹:")
        print("      â€¢ TÄƒng regularization (alpha)")
        print("      â€¢ Giáº£m sá»‘ lÆ°á»£ng features")
        print("      â€¢ Thu tháº­p thÃªm dá»¯ liá»‡u training")
        print("      â€¢ Sá»­ dá»¥ng cross-validation")
    elif max_gap > 0.05:
        print("   âš ï¸  CÃ³ dáº¥u hiá»‡u overfitting nháº¹")
        print("   ğŸ“‹ Khuyáº¿n nghá»‹: Theo dÃµi vÃ  cÃ³ thá»ƒ tÄƒng nháº¹ regularization")
    else:
        print("   âœ… KhÃ´ng cÃ³ dáº¥u hiá»‡u overfitting Ä‘Ã¡ng ká»ƒ")

    # 3. PhÃ¢n tÃ­ch xu hÆ°á»›ng
    print("\n3. PHÃ‚N TÃCH XU HÆ¯á»šNG:")

    # Xu hÆ°á»›ng train score
    if len(train_scores) >= 3:
        train_trend = np.polyfit(range(len(train_scores)), train_scores, 1)[0]
        test_trend = np.polyfit(range(len(test_scores)), test_scores, 1)[0]

        print(f"   - Xu hÆ°á»›ng Train accuracy: {train_trend:+.6f}/step")
        print(f"   - Xu hÆ°á»›ng Test accuracy: {test_trend:+.6f}/step")

        if test_trend > 0.001:
            print("   ğŸ“ˆ Test accuracy Ä‘ang tÄƒng - cÃ³ thá»ƒ cáº§n thÃªm dá»¯ liá»‡u")
        elif test_trend < -0.001:
            print("   ğŸ“‰ Test accuracy Ä‘ang giáº£m - cÃ³ dáº¥u hiá»‡u overfitting")
        else:
            print("   â¡ï¸  Test accuracy á»•n Ä‘á»‹nh - mÃ´ hÃ¬nh Ä‘Ã£ há»™i tá»¥")

    # 4. Khuyáº¿n nghá»‹ tá»•ng quÃ¡t
    print("\n4. KHUYáº¾N NGHá»Š Tá»”NG QUÃT:")

    final_train_score = train_scores[-1]
    final_test_score = test_scores[-1]
    final_gap = final_train_score - final_test_score

    if final_test_score > 0.9:
        print("   ğŸ¯ Hiá»‡u suáº¥t tá»‘t!")
    elif final_test_score > 0.8:
        print("   ğŸ‘ Hiá»‡u suáº¥t khÃ¡ tá»‘t")
    else:
        print("   ğŸ”§ Cáº§n cáº£i thiá»‡n hiá»‡u suáº¥t")

    if final_gap < 0.03:
        print("   âš–ï¸  MÃ´ hÃ¬nh cÃ¢n báº±ng tá»‘t")
    elif final_gap < 0.1:
        print("   âš–ï¸  MÃ´ hÃ¬nh tÆ°Æ¡ng Ä‘á»‘i cÃ¢n báº±ng")
    else:
        print("   âš ï¸  MÃ´ hÃ¬nh khÃ´ng cÃ¢n báº±ng - cáº§n Ä‘iá»u chá»‰nh")

    # 5. Thá»‘ng kÃª chi tiáº¿t
    print(f"\n5. THá»NG KÃŠ CHI TIáº¾T:")
    print(f"   - KÃ­ch thÆ°á»›c training nhá» nháº¥t: {min(train_sizes):,}")
    print(f"   - KÃ­ch thÆ°á»›c training lá»›n nháº¥t: {max(train_sizes):,}")
    print(f"   - Train accuracy cuá»‘i: {final_train_score:.4f}")
    print(f"   - Test accuracy cuá»‘i: {final_test_score:.4f}")
    print(f"   - Thá»i gian fit trung bÃ¬nh: {np.mean(results['fit_times_mean']):.2f}s")

# HÃ m sá»­ dá»¥ng vá»›i dá»¯ liá»‡u thá»±c táº¿
def run_learning_curve_analysis():
    """
    Cháº¡y phÃ¢n tÃ­ch learning curve vá»›i dá»¯ liá»‡u thá»±c táº¿
    """
    from src.main.python.models.data import DataLoaderFactory
    from src.main.python.models.text_processor import TextProcessor
    from src.main.python.algorithms.classification.naive_bayes import NaiveBayes
    from src.main.python.algorithms.classification.naive_bayes_cuda_optimized import NaiveBayesCUDAOptimized

    print("=== PHÃ‚N TÃCH LEARNING CURVE CHO NAIVE BAYES ===")

    # Load dá»¯ liá»‡u
    print("Äang táº£i dá»¯ liá»‡u...")
    loader = DataLoaderFactory.create_loader(
        "huggingface",
        dataset_name="papluca/language-identification",
    )
    x_train, y_train = loader.load_data(loader.dataset_name, "train")
    x_test, y_test = loader.load_data(loader.dataset_name, "test")

    # Chuáº©n bá»‹ text processor
    print("Äang chuáº©n bá»‹ text processor...")
    text_processor = TextProcessor(ngram_range=(1, 3), max_features=5000)
    text_processor.fit_transform(x_train)

    # Cháº¡y learning curve cho CPU model
    print("\n" + "="*50)
    print("LEARNING CURVE CHO NAIVE BAYES (CPU)")
    print("="*50)

    cpu_results = learning_curve(
        model_class=NaiveBayes,
        x_data=x_train,
        y_data=y_train,
        x_test=x_test,
        y_test=y_test,
        text_processor=text_processor,
        train_sizes=[100, 200, 500, 1000, 1500, 2000, 2500, 3000],
        cv_folds=3,
        model_params={'alpha': 0.001},
        title="Learning Curve - Naive Bayes (CPU)",
        figsize=(12, 8)
    )

    # Cháº¡y learning curve cho GPU model (náº¿u cÃ³)
    try:
        print("\n" + "="*50)
        print("LEARNING CURVE CHO NAIVE BAYES CUDA (GPU)")
        print("="*50)

        gpu_results = learning_curve(
            model_class=NaiveBayesCUDAOptimized,
            x_data=x_train,
            y_data=y_train,
            x_test=x_test,
            y_test=y_test,
            text_processor=text_processor,
            train_sizes=[100, 200, 500, 1000, 1500, 2000, 2500, 3000],
            cv_folds=3,
            model_params={'alpha': 0.001, 'use_gpu': True},
            title="Learning Curve - Naive Bayes CUDA (GPU)",
            figsize=(12, 8)
        )

        # So sÃ¡nh CPU vs GPU
        compare_cpu_gpu_performance(cpu_results, gpu_results)

    except Exception as e:
        print(f"KhÃ´ng thá»ƒ cháº¡y GPU learning curve: {e}")

    return cpu_results

def compare_cpu_gpu_performance(cpu_results, gpu_results):
    """So sÃ¡nh hiá»‡u suáº¥t giá»¯a CPU vÃ  GPU"""

    print("\n" + "="*50)
    print("SO SÃNH HIá»†U SUáº¤T CPU vs GPU")
    print("="*50)

    # So sÃ¡nh thá»i gian training
    cpu_times = np.array(cpu_results['fit_times_mean'])
    gpu_times = np.array(gpu_results['fit_times_mean'])

    print(f"Thá»i gian training trung bÃ¬nh:")
    print(f"  CPU: {np.mean(cpu_times):.2f}s Â± {np.std(cpu_times):.2f}s")
    print(f"  GPU: {np.mean(gpu_times):.2f}s Â± {np.std(gpu_times):.2f}s")
    print(f"  Speedup: {np.mean(cpu_times)/np.mean(gpu_times):.2f}x")

    # So sÃ¡nh accuracy
    cpu_final_acc = cpu_results['test_scores_mean'][-1]
    gpu_final_acc = gpu_results['test_scores_mean'][-1]

    print(f"\nAccuracy cuá»‘i cÃ¹ng:")
    print(f"  CPU: {cpu_final_acc:.4f}")
    print(f"  GPU: {gpu_final_acc:.4f}")
    print(f"  ChÃªnh lá»‡ch: {abs(gpu_final_acc - cpu_final_acc):.4f}")

    # Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh
    plt.figure(figsize=(15, 5))

    # Subplot 1: So sÃ¡nh accuracy
    plt.subplot(1, 3, 1)
    train_sizes = cpu_results['train_sizes']
    plt.plot(train_sizes, cpu_results['test_scores_mean'], 'o-', label='CPU', linewidth=2)
    plt.plot(train_sizes, gpu_results['test_scores_mean'], 's-', label='GPU', linewidth=2)
    plt.xlabel('Training Size')
    plt.ylabel('Test Accuracy')
    plt.title('Accuracy Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Subplot 2: So sÃ¡nh thá»i gian training
    plt.subplot(1, 3, 2)
    plt.plot(train_sizes, cpu_times, 'o-', label='CPU', linewidth=2)
    plt.plot(train_sizes, gpu_times, 's-', label='GPU', linewidth=2)
    plt.xlabel('Training Size')
    plt.ylabel('Training Time (s)')
    plt.title('Training Time Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Subplot 3: Speedup
    plt.subplot(1, 3, 3)
    speedup = cpu_times / gpu_times
    plt.plot(train_sizes, speedup, 'g^-', linewidth=2, markersize=8)
    plt.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='No speedup')
    plt.xlabel('Training Size')
    plt.ylabel('Speedup (CPU time / GPU time)')
    plt.title('GPU Speedup')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # Cháº¡y phÃ¢n tÃ­ch learning curve
    results = run_learning_curve_analysis()